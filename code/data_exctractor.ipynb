{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_exctractor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnSEjkSZ1X3q",
        "colab_type": "text"
      },
      "source": [
        "# Extract Data From Scraped JSON Files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDCzkbxR48Yq",
        "colab_type": "text"
      },
      "source": [
        "## Load Crawled Data and Build Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q_0q-7U2dgE",
        "colab_type": "text"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_DRmlGn1nag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import Counter, defaultdict\n",
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import matplotlib\n",
        "import matplotlib.dates as mdates\n",
        "from textblob import TextBlob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2GV42eO2foA",
        "colab_type": "text"
      },
      "source": [
        "### Mounting (need to copy data to own Google Drive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zquKFh9TyJ5l",
        "colab_type": "code",
        "outputId": "992a1cd5-de47-4179-d59d-9d706bebf600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "dir = \"gdrive/My Drive/10kparagraphs\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLrKcmlXLuNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## sentiment analysis\n",
        "def sentiment_analysis(text, paragraph_mentions = None):\n",
        "\n",
        "  if paragraph_mentions != None:\n",
        "\n",
        "    paragraph_i = np.argmax(paragraph_mentions)\n",
        "    text = text[paragraph_i]\n",
        "\n",
        "  blob = TextBlob(str(text))\n",
        "  text_polarity = blob.sentiment.polarity\n",
        "  text_subjectivity = blob.sentiment.subjectivity\n",
        "\n",
        "  return text_polarity, text_subjectivity\n",
        "\n",
        "\n",
        "\n",
        "## word count\n",
        "def get_word_counts(text, keywords):\n",
        "\n",
        "  text = text.lower()\n",
        "\n",
        "  corona_count = 0\n",
        "  n_words = len(text.split(\" \"))\n",
        "\n",
        "  ## corona mention feature\n",
        "  for k in keywords:\n",
        "    corona_count += text.count(str(k))\n",
        "\n",
        "  return corona_count, n_words\n",
        "\n",
        "\n",
        "## get relative word count\n",
        "def get_relative_count(word_count, n_words):\n",
        "\n",
        "    rel_word_count = 0\n",
        "\n",
        "    if n_words >= 1:\n",
        "      rel_word_count = word_count / n_words\n",
        "\n",
        "    return rel_word_count\n",
        "\n",
        "\n",
        "\n",
        "## get name features\n",
        "def get_name_features(filename):\n",
        "\n",
        "  ## date-SIC-FirmID.JSON\n",
        "  filename_arr = filename.split(\"_\")\n",
        "  date_str = filename_arr[0]\n",
        "  datetime_object = datetime.strptime(date_str, '%Y%m%d')\n",
        "  SIC = filename_arr[1]\n",
        "  FirmID = filename_arr[2].split(\".\")[0]\n",
        "\n",
        "  return datetime_object, SIC, FirmID\n",
        "\n",
        "\n",
        "## get content features\n",
        "def get_content_features(json_dict, keywords):\n",
        "\n",
        "  corona_count = 0 \n",
        "  rel_corona_count = float(0.0)\n",
        "  paragraph_texts = []\n",
        "  complete_text = ''\n",
        "  paragraph_mentions = []\n",
        "  paragraph_words = []\n",
        "  paragraph_polarity = float(0.0)\n",
        "  paragraph_subjectivity = float(0.0)\n",
        "  report_polarity = float(0.0)\n",
        "  report_subjectivity = float(0.0)\n",
        "\n",
        "\n",
        "  if '0' in json_dict.keys(): ## article contains data\n",
        "    paragraphs = json_dict['0'].keys()\n",
        "\n",
        "    for p in paragraphs:\n",
        "\n",
        "      corona_mentions = 0\n",
        "      text = json_dict['0'][p]\n",
        "\n",
        "      if type(text) == str:\n",
        "        paragraph_texts.append(text)\n",
        "        complete_text += (\" \" + text)\n",
        "\n",
        "        corona_count, n_words = get_word_counts(text, keywords)\n",
        "        paragraph_mentions.append(corona_count)\n",
        "        paragraph_words.append(n_words)\n",
        "    \n",
        "    ## total corona countd over all paragraphs\n",
        "    corona_count = sum(paragraph_mentions)\n",
        "    n_words = sum(paragraph_words)\n",
        "    rel_corona_count = get_relative_count(corona_count, n_words)\n",
        "\n",
        "    report_polarity, report_subjectivity = sentiment_analysis(complete_text)\n",
        "    paragraph_polarity, paragraph_subjectivity = sentiment_analysis(paragraph_texts, paragraph_mentions)\n",
        "\n",
        "  return corona_count, rel_corona_count, paragraph_mentions, paragraph_polarity, paragraph_subjectivity, report_polarity, report_subjectivity, paragraph_texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts-fLLd9zi3D",
        "colab_type": "code",
        "outputId": "000a929a-3eec-4b9c-9040-4276dbff496d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = pd.DataFrame(columns=['JSON_file','date', 'SIC', 'FirmID','corona_mentions','corona_count','rel_corona_count','raw_text'])\n",
        "keywords = [\"corona\",\"covid\"]\n",
        "\n",
        "for filename in tqdm(os.listdir(dir)):\n",
        "    if filename.endswith(\".JSON\"):\n",
        "      \n",
        "        json_path = os.path.join(dir, filename)\n",
        "        datetime_object, SIC, FirmID = get_name_features(filename)\n",
        "\n",
        "        with open(json_path) as f:\n",
        "            json_dict = json.load(f)\n",
        "            corona_count, rel_corona_count, paragraph_mentions, paragraph_polarity, paragraph_subjectivity, report_polarity, report_subjectivity, paragraph_texts = get_content_features(json_dict, keywords)\n",
        "\n",
        "        ## append everything to Dataframe\n",
        "        df = df.append({\"JSON_file\": filename, \"date\": datetime_object, \"FirmID\": FirmID, \"SIC\":  SIC, \"corona_mentions\": paragraph_mentions, \"paragraph_sentiment\": paragraph_polarity, \"paragraph_subjectivity\": paragraph_subjectivity, \"report_sentiment\": report_polarity, \"report_subjectivity\": report_subjectivity, \"corona_count\": corona_count, \"rel_corona_count\": round(rel_corona_count,4), \"raw_text\": paragraph_texts}, ignore_index=True)\n",
        "\n",
        "    else:\n",
        "        continue"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1763/1763 [10:34<00:00,  2.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNK2YZPyposL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_pickle(\"gdrive/My Drive/k_10_corona.pkl\")\n",
        "df_no_text = df.drop(columns=[\"raw_text\"])\n",
        "df_no_text.to_csv(\"gdrive/My Drive/k_10_corona.csv\", encoding = 'utf-8', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}