{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Statistics for 10K Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load packages\n",
    "import re\n",
    "import numpy as np\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.rrule import rrule, DAILY\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from __future__ import division\n",
    "import random\n",
    "pd.set_option('display.max_colwidth', -1) # For displaying all entries in full length in pandas\n",
    "\n",
    "# Clean txt raw files\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});|\\n|\\t')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of all SEC reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabianbraesemann/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:14: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \n",
      "/Users/fabianbraesemann/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/fabianbraesemann/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64f67f8412945c9922900de01b4f853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully parsed 322905 reports for 2020-Q1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf16fb50bbdb420fa090c4cd510e4457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully parsed 501609 reports for 2020-Q2\n"
     ]
    }
   ],
   "source": [
    "# Retrieve reports' meta-data from SEC repository\n",
    "## Prepare empty df to store report meta-data\n",
    "df_ix = {\n",
    "    \"cik\":[],\n",
    "    \"name\":[],\n",
    "    \"form\":[],\n",
    "    \"date\":[],\n",
    "    \"link\":[],\n",
    "    \"quarter\":[]\n",
    "}\n",
    "\n",
    "## Parse across quarters for 2020 to get CIK, NAME, FORM, DATE, and LINK\n",
    "for q in [1,2]:\n",
    "    indexfile = pd.read_table(\"https://www.sec.gov/Archives/edgar/full-index/2020/QTR\" + str(q) +\"/master.idx\")    \n",
    "    indexfile = indexfile.ix[6:,0]\n",
    "    \n",
    "    for entry in tqdm(indexfile):\n",
    "        \n",
    "        df_ix[\"quarter\"].append(q)\n",
    "        \n",
    "        items = entry.split(\"|\")\n",
    "        df_ix[\"cik\"].append(items[0])\n",
    "        df_ix[\"name\"].append(items[1])\n",
    "        df_ix[\"form\"].append(items[2])\n",
    "        df_ix[\"date\"].append(items[3])\n",
    "        df_ix[\"link\"].append(\"https://www.sec.gov/Archives/\" + items[4].replace(\".txt\",\"-index.htm\"))\n",
    "        \n",
    "    print(\"Successfully parsed \" + str(len(df_ix[\"cik\"])) + \" reports for 2020-Q\" + str(q))\n",
    "    \n",
    "## Store report list for 2020\n",
    "report_index = pd.DataFrame(df_ix)\n",
    "report_index.to_csv(os.getcwd() + \"/10x_report_list.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape only new reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 28763 new reports since 2020-05-21\n"
     ]
    }
   ],
   "source": [
    "# Get stats of already scraped reports\n",
    "old_report_sentences = pd.read_csv(os.getcwd().replace(\"/Scraping\", \"\") + \"/Processing/10x_report_sentences.csv\", index_col=0)\n",
    "# Keep only most recent reports\n",
    "report_index = report_index[report_index[\"date\"]>=max(old_report_sentences[\"date\"])]\n",
    "print(\"Got \" + str(len(report_index[\"date\"])) + \" new reports since \" + str(max(old_report_sentences[\"date\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find HTML link for 10-K and 10-Q reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabianbraesemann/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/fabianbraesemann/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/fabianbraesemann/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6e337b60b048af9bed8512481ff766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabianbraesemann/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/Users/fabianbraesemann/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/fabianbraesemann/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully retrieved 249 report links and appended\n"
     ]
    }
   ],
   "source": [
    "# Read report list\n",
    "reports_10x = report_index[(report_index[\"form\"] == \"10-K\") | (report_index[\"form\"]==\"10-Q\")]\n",
    "\n",
    "# Find report links\n",
    "reports_10x[\"sic\"] = \"na\"\n",
    "reports_10x[\"report_link\"] = \"na\"\n",
    "\n",
    "#for i in tqdm(range(0,len(reports_10x))):\n",
    "for x in tqdm(range(len(reports_10x.index))):\n",
    "        \n",
    "    try:\n",
    "        r = requests.get(reports_10x[\"link\"].iloc[x])\n",
    "        soup = BeautifulSoup(r.content, \"lxml\") \n",
    "\n",
    "        reports_10x[\"report_link\"].iloc[x] = (soup.find_all(\"div\", {\"id\": \"formDiv\"})[1].\n",
    "                               find('a', href=True).attrs[\"href\"].replace(\"/ix?doc=\",\"\"))\n",
    "        reports_10x[\"sic\"].iloc[x] = str(soup.find(\"div\", {\"class\": \"companyInfo\"}).find_all(\"a\")[2].text)\n",
    "    except:\n",
    "        pass\n",
    "       \n",
    "# Append newly scraped report info remove potential duplicates\n",
    "df = pd.read_csv(os.getcwd() + \"/10x_report_links.csv\", index_col=0).append(reports_10x)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Store extended file as CSV\n",
    "df.to_csv(os.getcwd() + \"/10x_report_links.csv\")\n",
    "print(\"Successfully retrieved \" + str(len(reports_10x[\"report_link\"])) + \" report links and appended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve sentences for selected reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabianbraesemann/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e48f006468a416599ddac6c77e8bd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'pandas.core.frame.DataFrame'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c0e00e48cc63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Append new DF to old DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mreport_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_report_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;31m# Drop potential duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mreport_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreport_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fabianbraesemann/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fabianbraesemann/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     filepath_or_buffer, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 413\u001b[0;31m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fabianbraesemann/anaconda2/lib/python2.7/site-packages/pandas/io/common.pyc\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Invalid file path or buffer object type: {_type}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'pandas.core.frame.DataFrame'>"
     ]
    }
   ],
   "source": [
    "# Parse through 10x html reports\n",
    "# Define \"corona\" keywords \n",
    "corona_words = [\"corona\",\"covid\"]\n",
    "\n",
    "## Prepare DF for storage\n",
    "df = {\n",
    "    \"cik\":[],\n",
    "    \"sic\":[],\n",
    "    \"date\":[],\n",
    "    \"name\":[],\n",
    "    \"form\":[],\n",
    "    \"report_link\":[],\n",
    "    \"report_word_count\":[],\n",
    "    \"report_corona_count\":[],\n",
    "    \"sentence_text\":[]\n",
    "}\n",
    "\n",
    "## Open html reports and get stats\n",
    "for x in tqdm(range(0,len(reports_10x))):\n",
    "    \n",
    "    ### Open reports\n",
    "    r = reports_10x[\"report_link\"].iloc[x]\n",
    "    url = \"https://www.sec.gov\" + r\n",
    "    u = requests.get(url)    \n",
    "    soup = BeautifulSoup(u.content, \"lxml\") \n",
    "    text = soup.text.replace(\"\\n\",\"\")\n",
    "    text = text.lower()\n",
    "\n",
    "    ### Corona count\n",
    "    report_corona_count = sum([text.count(word) for word in corona_words])\n",
    "    report_word_count = len(re.findall(r'\\w+', text))\n",
    "\n",
    "    if report_corona_count == 0:\n",
    "        \n",
    "        df[\"date\"].append(reports_10x[\"date\"].iloc[x])\n",
    "        df[\"sic\"].append(reports_10x[\"sic\"].iloc[x])\n",
    "        df[\"cik\"].append(reports_10x[\"cik\"].iloc[x])\n",
    "        df[\"name\"].append(reports_10x[\"name\"].iloc[x])\n",
    "        df[\"form\"].append(reports_10x[\"form\"].iloc[x])\n",
    "        \n",
    "        df[\"report_link\"].append(r)\n",
    "        df[\"report_corona_count\"].append(report_corona_count)\n",
    "        df[\"report_word_count\"].append(report_word_count)\n",
    "        df[\"sentence_text\"].append(\"na\")\n",
    "\n",
    "    else:\n",
    "    ### Get corona sentences\n",
    "        corona_sentences = [sentence + '.' for sentence in text.split('.') if 'corona' in sentence or 'covid' in sentence]\n",
    "\n",
    "        for sentence in corona_sentences:\n",
    "\n",
    "            ## Get sentence info\n",
    "            sentence_word_count = len(re.findall(r'\\w+', sentence))\n",
    "\n",
    "            df[\"date\"].append(reports_10x[\"date\"].iloc[x])\n",
    "            df[\"sic\"].append(reports_10x[\"sic\"].iloc[x])\n",
    "            df[\"cik\"].append(reports_10x[\"cik\"].iloc[x])\n",
    "            df[\"name\"].append(reports_10x[\"name\"].iloc[x])\n",
    "            df[\"form\"].append(reports_10x[\"form\"].iloc[x])\n",
    "            \n",
    "            df[\"report_link\"].append(r)\n",
    "            df[\"report_corona_count\"].append(report_corona_count)\n",
    "            df[\"report_word_count\"].append(report_word_count)\n",
    "            df[\"sentence_text\"].append(sentence.encode(\"utf-8\"))\n",
    "    \n",
    "# Turn DF into pandas\n",
    "df = pd.DataFrame(df) \n",
    "# Append new DF to old DF\n",
    "report_sentences = old_report_sentences.append(df)\n",
    "# Drop potential duplicates\n",
    "report_sentences = report_sentences.drop_duplicates()\n",
    "# Store all sentences as csv\n",
    "report_sentences.to_csv(os.getcwd().replace(\"/Scraping\", \"\") + \"/Processing/10x_report_sentences.csv\")\n",
    "print(str(len(df[\"sentence_text\"])) + \" new sentences retrieved and appended\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
